{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyBreakDown.explainer import Explainer\n",
    "from pyBreakDown.explanation import Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for fraud observations  with step -down approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "  Feature Norm_Contribution(Abs) Feature Norm_Contribution(Abs) Feature  \\\n",
      "0     V11               0.509274     V11               0.502909     V14   \n",
      "1      V4               0.326764      V4                0.30732     V13   \n",
      "2      V3              0.0813275      V9              0.0866495      V9   \n",
      "3      V9              0.0688917      V3              0.0708256     V15   \n",
      "4     V14             0.00658144     V17              0.0234013     V18   \n",
      "\n",
      "  Norm_Contribution(Abs) Feature Norm_Contribution(Abs) Feature  \\\n",
      "0               0.628743     V17               0.724551     V18   \n",
      "1               0.197605     V14               0.209581     V16   \n",
      "2               0.134731  Amount              0.0419162     V25   \n",
      "3              0.0179641     V21              0.0179641     V27   \n",
      "4               0.011976     V26             0.00299401      V2   \n",
      "\n",
      "  Norm_Contribution(Abs)  ... Feature Norm_Contribution(Abs) Feature  \\\n",
      "0               0.802395  ...     V11               0.510154     V11   \n",
      "1              0.0958084  ...      V4               0.327354      V4   \n",
      "2              0.0778443  ...      V3              0.0812748      V3   \n",
      "3              0.0239521  ...      V9              0.0674796      V9   \n",
      "4                      0  ...     V14             0.00657617     V17   \n",
      "\n",
      "  Norm_Contribution(Abs) Feature Norm_Contribution(Abs) Feature  \\\n",
      "0               0.509211     V14               0.949102     V11   \n",
      "1               0.304575     V17              0.0239521      V3   \n",
      "2              0.0813117  Amount              0.0239521     V17   \n",
      "3              0.0755786     V28             0.00299401      V9   \n",
      "4              0.0186905      V2                      0      V4   \n",
      "\n",
      "  Norm_Contribution(Abs) Feature Norm_Contribution(Abs)  \n",
      "0               0.500759     V11               0.510186  \n",
      "1               0.222346      V4               0.327328  \n",
      "2               0.183743      V3              0.0812695  \n",
      "3               0.047477      V9              0.0674796  \n",
      "4              0.0371807     V14             0.00657617  \n",
      "\n",
      "[5 rows x 300 columns]\n",
      "CPU times: user 11d 5h 31min 32s, sys: 5h 37min 3s, total: 11d 11h 8min 35s\n",
      "Wall time: 1d 17h 52min 6s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyBreakDown.explainer import Explainer\n",
    "from pyBreakDown.explanation import Explanation\n",
    "\n",
    "loaded_class1x = pickle.load(open('./Data/PickledData300/class1X.pickle', 'rb'))\n",
    "loaded_RFmodel = pickle.load(open('./SavedRFModel/Python_RF.pickle', 'rb'))\n",
    "loaded_exp = pickle.load(open('./Data/SavedExplainers/pybreakdownExplainer.pkl', 'rb'))\n",
    "\n",
    "columnnames = np.array(loaded_class1x.columns)\n",
    "datatopyBreak = loaded_class1x[0:150]\n",
    "\n",
    "Result = pd.DataFrame()\n",
    "R_norm = pd.DataFrame()\n",
    "R_norm_TOP5 = pd.DataFrame()\n",
    "\n",
    "for i in range(len(datatopyBreak)):\n",
    "    print(i)\n",
    "    explanationu = loaded_exp.explain(observation=loaded_class1x.iloc[i],direction=\"down\")\n",
    "    pyBru = explanationu._attributes\n",
    "    pyBru = pd.DataFrame(pyBru, columns = ['Feature', 'Value', 'Contribution', 'Cumulative'])\n",
    "    pyBru = pyBru.drop(['Value', 'Cumulative'], axis=1)\n",
    "    pyBru = pyBru.tail(-1)\n",
    "    pyBru_array = pyBru.to_numpy()\n",
    "    pyBru_sortArray = pyBru_array[pyBru_array[:,1].argsort()]\n",
    "    pyBru_sortedArray = pyBru_sortArray[::-1]\n",
    "    df = pd.DataFrame(data=pyBru_sortedArray, columns=[\"Feature\", \"Contribution\"])\n",
    "    Result = pd.concat([Result, df], axis=1)\n",
    "    \n",
    "    #take absolute of contribution column and sum, then divide each row(abs) by the sum.\n",
    "    contrAbs = df['Contribution'].abs()\n",
    "    df['Abs_contribution'] = contrAbs\n",
    "    absSum = df['Abs_contribution'].sum()\n",
    "    #New_Norm_Contribution column sum up to 1\n",
    "    df['New_Norm_Contribution'] = df['Abs_contribution']/absSum\n",
    "    df_norm = df[['Feature','New_Norm_Contribution']]\n",
    "    \n",
    "    df_norm = df_norm.to_numpy()\n",
    "    df_norm = df_norm[df_norm[:,1].argsort()]\n",
    "    df_norm = df_norm[::-1]\n",
    "    df_norm = pd.DataFrame(data=df_norm, columns=[\"Feature\", \"Norm_Contribution(Abs)\"])\n",
    "    \n",
    "    R_norm = pd.concat([R_norm, df_norm], axis=1)\n",
    "    R_norm_TOP5 = R_norm.head(5)\n",
    "    \n",
    "#Result.to_csv('pyBDown_fraud_originalweights.csv', index = False, header=True, sep = \"\\t\")\n",
    "R_norm.to_csv('pyBDown_ALL_NORM_fraud.csv', index = False, header=True, sep = \"\\t\")\n",
    "#R_norm_TOP5.to_csv('pyBDown_NORM_TOP5_fraud.csv', index = False, header=True, sep = \"\\t\")\n",
    "print(R_norm_TOP5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  for fraud observations  with step - up approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "  Feature Norm_Contribution(Abs) Feature Norm_Contribution(Abs) Feature  \\\n",
      "0      V4               0.566284      V4               0.362696     V14   \n",
      "1      V3               0.281786     V14               0.320064     V13   \n",
      "2     V12              0.0957493     V11               0.310393      V9   \n",
      "3     V11              0.0478009     V10             0.00564638      V4   \n",
      "4     V14             0.00756387     V12            0.000484578     V15   \n",
      "\n",
      "  Norm_Contribution(Abs) Feature Norm_Contribution(Abs) Feature  \\\n",
      "0               0.628743     V12               0.826347     V10   \n",
      "1               0.197605      V4               0.170659     V16   \n",
      "2               0.134731      V1             0.00299401     V25   \n",
      "3              0.0299401     V14                      0     V24   \n",
      "4             0.00598802     V28                      0     V28   \n",
      "\n",
      "  Norm_Contribution(Abs)  ... Feature Norm_Contribution(Abs) Feature  \\\n",
      "0               0.823353  ...      V4               0.369093      V4   \n",
      "1              0.0958084  ...     V11               0.318822      V3   \n",
      "2              0.0479042  ...     V14               0.305169     V11   \n",
      "3              0.0329341  ...     V10             0.00598361     V14   \n",
      "4                      0  ...     V12            0.000521459     V10   \n",
      "\n",
      "  Norm_Contribution(Abs) Feature Norm_Contribution(Abs) Feature  \\\n",
      "0                0.39598     V14               0.949102      V4   \n",
      "1               0.256173     V10              0.0419162     V14   \n",
      "2               0.235984      V2             0.00898204     V11   \n",
      "3               0.105179     V13                      0     V10   \n",
      "4             0.00568876     V28                      0     V16   \n",
      "\n",
      "  Norm_Contribution(Abs) Feature Norm_Contribution(Abs)  \n",
      "0               0.360576      V4               0.410472  \n",
      "1               0.331848     V14               0.331637  \n",
      "2               0.300275     V11               0.250158  \n",
      "3             0.00585738     V10             0.00659461  \n",
      "4            0.000732172     V12            0.000732149  \n",
      "\n",
      "[5 rows x 300 columns]\n",
      "CPU times: user 9d 18h 19min 38s, sys: 5h 43min 57s, total: 10d 3min 36s\n",
      "Wall time: 1d 18h 58min 33s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyBreakDown.explainer import Explainer\n",
    "from pyBreakDown.explanation import Explanation\n",
    "\n",
    "loaded_class1x = pickle.load(open('./Data/PickledData300/class1X.pickle', 'rb'))\n",
    "loaded_RFmodel = pickle.load(open('./SavedRFModel/Python_RF.pickle', 'rb'))\n",
    "loaded_exp = pickle.load(open('./SavedExplainers/pybreakdownExplainer.pkl', 'rb'))\n",
    "\n",
    "columnnames = np.array(loaded_class1x.columns)\n",
    "datatopyBreak = loaded_class1x[0:150]\n",
    "\n",
    "Result = pd.DataFrame()\n",
    "R_norm = pd.DataFrame()\n",
    "R_norm_TOP5 = pd.DataFrame()\n",
    "\n",
    "for i in range(len(datatopyBreak)):\n",
    "    print(i)\n",
    "    explanationu = loaded_exp.explain(observation=loaded_class1x.iloc[i],direction=\"up\")\n",
    "    pyBru = explanationu._attributes\n",
    "    pyBru = pd.DataFrame(pyBru, columns = ['Feature', 'Value', 'Contribution', 'Cumulative'])\n",
    "    pyBru = pyBru.drop(['Value', 'Cumulative'], axis=1)\n",
    "    pyBru = pyBru.tail(-1)\n",
    "    pyBru_array = pyBru.to_numpy()\n",
    "    pyBru_sortArray = pyBru_array[pyBru_array[:,1].argsort()]\n",
    "    pyBru_sortedArray = pyBru_sortArray[::-1]\n",
    "    df = pd.DataFrame(data=pyBru_sortedArray, columns=[\"Feature\", \"Contribution\"])\n",
    "    Result = pd.concat([Result, df], axis=1)\n",
    "    \n",
    "    #take absolute of contribution column and sum, then divide each row(abs) by the sum.\n",
    "    contrAbs = df['Contribution'].abs()\n",
    "    df['Abs_contribution'] = contrAbs\n",
    "    absSum = df['Abs_contribution'].sum()\n",
    "    #New_Norm_Contribution column sum up to 1\n",
    "    df['New_Norm_Contribution'] = df['Abs_contribution']/absSum\n",
    "    df_norm = df[['Feature','New_Norm_Contribution']]\n",
    "    \n",
    "    df_norm = df_norm.to_numpy()\n",
    "    df_norm = df_norm[df_norm[:,1].argsort()]\n",
    "    df_norm = df_norm[::-1]\n",
    "    df_norm = pd.DataFrame(data=df_norm, columns=[\"Feature\", \"Norm_Contribution(Abs)\"])\n",
    "    \n",
    "    R_norm = pd.concat([R_norm, df_norm], axis=1)\n",
    "    R_norm_TOP5 = R_norm.head(5)\n",
    "    \n",
    "#Result.to_csv('pyBup_fraud_originalweights.csv', index = False, header=True, sep = \"\\t\")\n",
    "R_norm.to_csv('pyBup_ALL_NORM_fraud.csv', index = False, header=True, sep = \"\\t\")\n",
    "#R_norm_TOP5.to_csv('pyBup_NORM_TOP5_fraud.csv', index = False, header=True, sep = \"\\t\")\n",
    "print(R_norm_TOP5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
